kafka-journal {

  # FQCN of the Kafka journal plugin
  class = "akka.persistence.kafka.journal.KafkaJournal"

  # Dispatcher for the plugin actor
  plugin-dispatcher = "akka.persistence.dispatchers.default-plugin-dispatcher"

  # Dispatcher for message replay
  replay-dispatcher = "akka.persistence.dispatchers.default-replay-dispatcher"

  partition = 0

  consumer {
    #
    # See also http://kafka.apache.org/documentation.html#consumerconfigs
    #

    socket.timeout.ms = 30000

    socket.receive.buffer.bytes = 65536

    fetch.message.max.bytes = 1048576
  }

  producer {
    #
    # See also http://kafka.apache.org/documentation.html#producerconfigs
    #

    #
    # The metadata.broker.list property is set dynamically by the journal.
    # No need to set it here.
    #

    # DO NOT CHANGE!
    producer.type = "sync"

    # DO NOT CHANGE!
    request.required.acks = 1

    # DO NOT CHANGE!
    partitioner.class = "akka.persistence.kafka.journal.StickyPartitioner"

    # DO NOT CHANGE!
    key.serializer.class = "kafka.serializer.StringEncoder"

    # Add further producer settings here, if needed ...
    # ...

  }

  event.producer {
    #
    # See also http://kafka.apache.org/documentation.html#producerconfigs
    #

    producer.type = "async"

    serializer.class = "akka.persistence.kafka.DefaultEventEncoder"

    # DO NOT CHANGE!
    key.serializer.class = "kafka.serializer.StringEncoder"

    topic.mapper.class = "akka.persistence.kafka.DefaultEventTopicMapper"
  }

  zookeeper {

    connect = "localhost:2181"

    session.timeout.ms = 6000

    connection.timeout.ms = 6000

    sync.time.ms = 2000
  }
}

test-server {

  zookeeper {

    port = 2181

    dir = "target/journal/zookeeper"
  }

  kafka {

    broker.id = 1

    num.partitions = 2

    port = 6667

    log.dirs = target/journal/kafka

    log.index.size.max.bytes = 1024
  }
}